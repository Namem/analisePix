{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061f08bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "#           ANÁLISE DE PADRÕES DE ANOMALIA EM TRANSAÇÕES PIX\n",
    "# ==============================================================================\n",
    "# Este script foi projetado para ler um arquivo de transações, aprender os\n",
    "# perfis de transações anômalas e, em seguida, gerar um novo arquivo CSV\n",
    "# contendo apenas as transações suspeitas, com uma explicação do motivo.\n",
    "# ==============================================================================\n",
    "\n",
    "# Importação das bibliotecas necessárias\n",
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# --- FASE 1: Carregamento e Exploração dos Dados ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"--- FASE 1: Carregamento e Exploração dos Dados ---\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n[OBJETIVO] O primeiro passo é carregar nosso arquivo CSV para a memória e fazer uma rápida inspeção para entender sua estrutura.\")\n",
    "\n",
    "df = pd.read_csv('comprovantes_pix_10000_anomalias.csv', sep=';')\n",
    "\n",
    "print(\"\\n[AÇÃO] Removendo colunas desnecessárias para a análise de padrões...\")\n",
    "\n",
    "# Lista das colunas que identificamos como não relevantes para encontrar padrões gerais\n",
    "colunas_para_remover = [\n",
    "    'EndToEndId', \n",
    "    'Moeda', \n",
    "    'Pagador_Nome', \n",
    "    'Pagador_CPF_CNPJ',\n",
    "    'Recebedor_Nome', \n",
    "    'Recebedor_CPF_CNPJ', \n",
    "    'ChavePix_Utilizada',\n",
    "    'Descricao'\n",
    "]\n",
    "\n",
    "# O comando .drop() remove as colunas da lista\n",
    "df = df.drop(columns=colunas_para_remover)\n",
    "\n",
    "print(f\"[SUCESSO] Colunas removidas. O DataFrame agora tem {df.shape[1]} colunas.\")\n",
    "print(\"[INFO] Verificando a estrutura do DataFrame após a limpeza:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165a3dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- FASE 2: Preparação dos Dados e Criação de Novas Features ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"--- FASE 2: Preparação dos Dados e Criação de Novas Features ---\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n[OBJETIVO] Dados brutos raramente estão prontos para análise. Vamos limpá-los e criar novas colunas (features) que ajudem o algoritmo a encontrar padrões.\")\n",
    "\n",
    "# Conversão da coluna de data e hora\n",
    "print(\"\\n[AÇÃO] Convertendo a coluna 'DataHora' para um formato de data que o Python entende...\")\n",
    "df['DataHora'] = pd.to_datetime(df['DataHora'], errors='coerce')\n",
    "df.dropna(subset=['DataHora'], inplace=True)\n",
    "print(\"[SUCESSO] 'DataHora' agora é uma coluna de data, permitindo extrair informações como hora, dia, etc.\")\n",
    "\n",
    "# Criação da coluna 'periodo_dia'\n",
    "print(\"\\n[AÇÃO] Criando uma nova coluna chamada 'periodo_dia' a partir da hora da transação...\")\n",
    "def get_periodo_dia(hour):\n",
    "    if 0 <= hour < 6: return 'Madrugada'\n",
    "    elif 6 <= hour < 12: return 'Manha'\n",
    "    elif 12 <= hour < 18: return 'Tarde'\n",
    "    else: return 'Noite'\n",
    "df['periodo_dia'] = df['DataHora'].dt.hour.apply(get_periodo_dia)\n",
    "print(\"[SUCESSO] Coluna 'periodo_dia' criada. Isso transforma a hora (numérica) em uma categoria (texto), o que é ótimo para encontrar regras.\")\n",
    "print(\"[ANÁLISE] Vamos ver a distribuição de transações por período:\")\n",
    "print(df['periodo_dia'].value_counts())\n",
    "\n",
    "# Criação da coluna 'valor_cat'\n",
    "print(\"\\n[AÇÃO] Criando a coluna 'valor_cat' para agrupar os valores das transações em faixas (Baixo, Medio, Alto)...\")\n",
    "df['valor_cat'] = pd.qcut(df['Valor'], q=3, labels=['Baixo', 'Medio', 'Alto'])\n",
    "print(\"[SUCESSO] Coluna 'valor_cat' criada. Agrupar valores ajuda o algoritmo a encontrar padrões como 'transações de baixo valor são suspeitas'.\")\n",
    "print(\"[ANÁLISE] Distribuição de transações por categoria de valor:\")\n",
    "print(df['valor_cat'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a652e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FASE 3: Transformando os Dados para o Formato de 'Cesta de Compras' ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"--- FASE 3: Transformando para o Formato de 'Cesta de Compras' ---\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n[OBJETIVO] O algoritmo que usaremos (Apriori) foi criado para analisar cestas de compras. Precisamos formatar nossos dados para que cada transação pareça uma 'cesta' e suas características (banco, status, etc.) pareçam 'itens' dentro dela.\")\n",
    "\n",
    "df_transacional = df[['Pagador_Banco', 'Recebedor_Banco', 'TipoChave', 'Status', 'periodo_dia', 'valor_cat', 'Anomalia']]\n",
    "\n",
    "records = []\n",
    "for i in range(len(df_transacional)):\n",
    "    records.append([str(col) + \"=\" + str(val) for col, val in df_transacional.iloc[i].items()])\n",
    "\n",
    "print(f\"\\n[SUCESSO] Dados convertidos para o formato de lista.\")\n",
    "print(\"[EXEMPLO] Uma transação que era uma linha na tabela, agora se parece com isto:\")\n",
    "print(records[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a68209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FASE 4: Encontrando Padrões Frequentes (Mineração) ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"--- FASE 4: Encontrando Padrões Frequentes (Mineração) ---\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n[OBJETIVO] Agora começa a 'mineração'. Vamos usar o algoritmo Apriori para ler todas as 'cestas' e encontrar combinações de 'itens' que aparecem com frequência.\")\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(records).transform(records)\n",
    "df_onehot = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "min_sup = 0.002\n",
    "frequent_itemsets = apriori(df_onehot, min_support=min_sup, use_colnames=True)\n",
    "print(f\"\\n[SUCESSO] O algoritmo Apriori analisou os dados com um suporte mínimo de {min_sup*100}%.\")\n",
    "print(\"O que isso significa? Ele buscou combinações de características que aparecem em pelo menos 0.2% de todas as transações.\")\n",
    "print(f\"\\n[RESULTADO] Foram encontrados {len(frequent_itemsets)} 'itemsets' (combinações) frequentes.\")\n",
    "print(\"[AMOSTRA] Abaixo estão os 10 itemsets mais comuns encontrados:\")\n",
    "print(frequent_itemsets.sort_values(by='support', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfae170e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- FASE 5: Gerando as Regras de Associação ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"--- FASE 5: Gerando as Regras de Associação ---\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n[OBJETIVO] Com os 'itemsets' frequentes em mãos, podemos agora gerar as 'regras de associação', que são as pérolas da nossa análise. Elas têm o formato 'SE acontecer X, ENTÃO provavelmente acontecerá Y'.\")\n",
    "\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.05)\n",
    "rules['consequents'] = rules['consequents'].apply(lambda x: list(x)[0]).astype(\"unicode\")\n",
    "rules_anomalia = rules[rules['consequents'] == 'Anomalia=1']\n",
    "rules_anomalia_sorted = rules_anomalia.sort_values(by='lift', ascending=False)\n",
    "\n",
    "print(\"\\n[SUCESSO] Regras geradas e filtradas para mostrar apenas aquelas que levam a uma anomalia.\")\n",
    "print(f\"[RESULTADO] Encontramos {len(rules_anomalia_sorted)} perfis de transações que são fortes indicadores de anomalia.\")\n",
    "print(\"\\n[INTERPRETAÇÃO] Como ler a tabela de regras abaixo:\")\n",
    "print(\" - 'antecedents' (SE...): As condições da transação.\")\n",
    "print(\" - 'consequents' (ENTÃO...): O resultado, que no nosso caso é sempre 'Anomalia=1'.\")\n",
    "print(\" - 'confidence': A 'taxa de acerto' da regra. Um valor de 1.0 significa 100% de certeza.\")\n",
    "print(\" - 'lift': A 'força' da regra. Um lift de 12 significa que a regra é 12x mais provável de indicar uma anomalia do que o acaso. É a métrica mais importante!\")\n",
    "print(\"\\n[AMOSTRA] As 5 regras mais fortes encontradas:\")\n",
    "print(rules_anomalia_sorted.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeece2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- FASE 6: Caça às Anomalias e Geração do CSV Final ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"--- FASE 6: Caça às Anomalias e Geração do CSV Final ---\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n[OBJETIVO] Agora, a parte mais prática! Vamos usar as regras que aprendemos para 'caçar' as transações suspeitas no nosso arquivo original e criar um relatório final em CSV.\")\n",
    "print(\"\\n[PROCESSO] O código irá varrer o arquivo de transações e, para cada uma, verificar se ela corresponde a algum dos perfis de anomalia encontrados...\")\n",
    "\n",
    "df['motivo_sinalizacao'] = None\n",
    "\n",
    "for index, rule in rules_anomalia_sorted.iterrows():\n",
    "    conditions = list(rule['antecedents'])\n",
    "    filtro_pandas = None\n",
    "    for i, condition in enumerate(conditions):\n",
    "        coluna, valor = condition.split('=', 1)\n",
    "        if df[coluna].dtype == 'int64': valor = int(valor)\n",
    "        elif df[coluna].dtype == 'float64': valor = float(valor)\n",
    "        if i == 0:\n",
    "            filtro_pandas = (df[coluna] == valor)\n",
    "        else:\n",
    "            filtro_pandas = filtro_pandas & (df[coluna] == valor)\n",
    "    motivo = f\"Regra (Força: {rule['lift']:.2f}): {' E '.join(conditions)}\"\n",
    "    df.loc[filtro_pandas & df['motivo_sinalizacao'].isnull(), 'motivo_sinalizacao'] = motivo\n",
    "\n",
    "df_anomalias_sugeridas = df.dropna(subset=['motivo_sinalizacao'])\n",
    "print(f\"\\n[ANÁLISE CONCLUÍDA] {len(df_anomalias_sugeridas)} transações foram sinalizadas como potencialmente anômalas.\")\n",
    "\n",
    "output_filename = 'transacoes_sinalizadas_como_anomalias.csv'\n",
    "df_anomalias_sugeridas.to_csv(output_filename, sep=';', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"--- RESULTADO FINAL ---\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n[SUCESSO TOTAL!] Um novo arquivo chamado '{output_filename}' foi criado na mesma pasta deste script.\")\n",
    "print(\"Este arquivo contém APENAS as transações suspeitas e uma nova coluna 'motivo_sinalizacao' que explica por que cada uma foi marcada.\")\n",
    "print(\"\\n[AMOSTRA DO ARQUIVO FINAL] Veja como ficou a saída:\")\n",
    "print(df_anomalias_sugeridas[['DataHora', 'Valor', 'Pagador_Banco', 'Status', 'Anomalia', 'motivo_sinalizacao']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5efb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# FASE FINAL: ANÁLISE PERCENTUAL E VISUALIZAÇÃO DETALHADA DAS ANOMALIAS\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"--- FASE FINAL: Análise Focada no Perfil das Anomalias ---\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Verificação para garantir que anomalias foram encontradas antes de prosseguir\n",
    "if 'df_anomalias_sugeridas' in locals() and not df_anomalias_sugeridas.empty:\n",
    "    print(f\"\\n[OBJETIVO] Analisar em detalhe o perfil das {len(df_anomalias_sugeridas)} transações sinalizadas como anomalias.\")\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "else:\n",
    "    print(\"Nenhuma anomalia foi sinalizada para análise. Execute as fases anteriores primeiro.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46764612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- GRÁFICO 1: Distribuição por Banco do Pagador ---\n",
    "if 'df_anomalias_sugeridas' in locals() and not df_anomalias_sugeridas.empty:\n",
    "    print(\"\\n[AÇÃO] Gerando Gráfico 1: Distribuição por Banco Pagador...\")\n",
    "    pagador_banco_full_percent = df_anomalias_sugeridas['Pagador_Banco'].value_counts(normalize=True) * 100\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x=pagador_banco_full_percent.values, y=pagador_banco_full_percent.index, palette='viridis', orient='h')\n",
    "    plt.title('Distribuição de Bancos Pagadores nas Anomalias (%)', fontsize=16)\n",
    "    plt.xlabel('Porcentagem de Transações Anômalas (%)', fontsize=12)\n",
    "    plt.ylabel('Banco do Pagador', fontsize=12)\n",
    "    plt.savefig('grafico_todos_bancos_anomalias.png', bbox_inches='tight')\n",
    "    print(\"[SUCESSO] Gráfico 'grafico_todos_bancos_anomalias.png' salvo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683960d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- GRÁFICO 2: Distribuição por Tipo de Chave PIX ---\n",
    "if 'df_anomalias_sugeridas' in locals() and not df_anomalias_sugeridas.empty:\n",
    "    print(\"\\n[AÇÃO] Gerando Gráfico 2: Distribuição por Tipo de Chave PIX...\")\n",
    "    tipo_chave_percent = df_anomalias_sugeridas['TipoChave'].value_counts(normalize=True) * 100\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=tipo_chave_percent.index, y=tipo_chave_percent.values, palette='plasma')\n",
    "    plt.title('Distribuição de Tipos de Chave nas Transações Anômalas', fontsize=16)\n",
    "    plt.xlabel('Tipo de Chave PIX', fontsize=12)\n",
    "    plt.ylabel('Porcentagem de Transações Anômalas (%)', fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.savefig('grafico_tipochave_anomalias.png', bbox_inches='tight')\n",
    "    print(\"[SUCESSO] Gráfico 'grafico_tipochave_anomalias.png' salvo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721b76d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- GRÁFICO 3: Distribuição por Status da Transação ---\n",
    "if 'df_anomalias_sugeridas' in locals() and not df_anomalias_sugeridas.empty:\n",
    "    print(\"\\n[AÇÃO] Gerando Gráfico 3: Distribuição por Status da Transação...\")\n",
    "    status_percent = df_anomalias_sugeridas['Status'].value_counts(normalize=True) * 100\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=status_percent.index, y=status_percent.values, palette='magma')\n",
    "    plt.title('Distribuição de Status nas Transações Anômalas', fontsize=16)\n",
    "    plt.xlabel('Status da Transação', fontsize=12)\n",
    "    plt.ylabel('Porcentagem de Transações Anômalas (%)', fontsize=12)\n",
    "    plt.savefig('grafico_status_anomalias.png', bbox_inches='tight')\n",
    "    print(\"[SUCESSO] Gráfico 'grafico_status_anomalias.png' salvo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a27e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- GRÁFICO 4: Histograma dos Valores das Fraudes ---\n",
    "if 'df_anomalias_sugeridas' in locals() and not df_anomalias_sugeridas.empty:\n",
    "    print(\"\\n[AÇÃO] Gerando Gráfico 4: Histograma dos Valores das Fraudes...\")\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    sns.histplot(data=df_anomalias_sugeridas, x='Valor', kde=True, bins=20, color='darkcyan')\n",
    "    plt.title('Distribuição dos Valores Monetários das Transações Anômalas', fontsize=16)\n",
    "    plt.xlabel('Valor da Transação (R$)', fontsize=12)\n",
    "    plt.ylabel('Contagem de Anomalias', fontsize=12)\n",
    "    plt.savefig('grafico_histograma_valores_anomalias.png', bbox_inches='tight')\n",
    "    print(\"[SUCESSO] Gráfico 'grafico_histograma_valores_anomalias.png' salvo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5229f8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- GRÁFICO 5: Contagem de Fraudes por Hora do Dia ---\n",
    "if 'df_anomalias_sugeridas' in locals() and not df_anomalias_sugeridas.empty:\n",
    "    print(\"\\n[AÇÃO] Gerando Gráfico 5: Contagem de Fraudes por Hora do Dia...\")\n",
    "    df_anomalias_sugeridas['hora'] = pd.to_datetime(df_anomalias_sugeridas['DataHora']).dt.hour\n",
    "    \n",
    "    plt.figure(figsize=(14, 7))\n",
    "    sns.countplot(data=df_anomalias_sugeridas, x='hora', palette='rocket', order=range(24))\n",
    "    plt.title('Contagem de Transações Anômalas por Hora do Dia', fontsize=16)\n",
    "    plt.xlabel('Hora do Dia (0-23h)', fontsize=12)\n",
    "    plt.ylabel('Contagem de Anomalias', fontsize=12)\n",
    "    plt.savefig('grafico_contagem_por_hora_anomalias.png', bbox_inches='tight')\n",
    "    print(\"[SUCESSO] Gráfico 'grafico_contagem_por_hora_anomalias.png' salvo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7fc30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- GRÁFICO 6: Heatmap Banco Pagador vs. Tipo de Chave ---\n",
    "if 'df_anomalias_sugeridas' in locals() and not df_anomalias_sugeridas.empty:\n",
    "    print(\"\\n[AÇÃO] Gerando Gráfico 6: Heatmap Banco Pagador vs. Tipo de Chave...\")\n",
    "    tabela_banco_chave = pd.crosstab(index=df_anomalias_sugeridas['Pagador_Banco'], columns=df_anomalias_sugeridas['TipoChave'])\n",
    "    \n",
    "    plt.figure(figsize=(14, 10))\n",
    "    sns.heatmap(tabela_banco_chave, annot=True, fmt='d', cmap='BuPu', linewidths=.5)\n",
    "    plt.title('Concentração de Anomalias: Banco Pagador vs. Tipo de Chave', fontsize=16)\n",
    "    plt.xlabel('Tipo de Chave PIX', fontsize=12)\n",
    "    plt.ylabel('Banco do Pagador', fontsize=12)\n",
    "    plt.savefig('grafico_heatmap_banco_chave.png', bbox_inches='tight')\n",
    "    print(\"[SUCESSO] Gráfico 'grafico_heatmap_banco_chave.png' salvo.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
